# AppSec GenAI - Evaluador de Vulnerabilidades OWASP

## Resumen del Reto

El desafÃ­o consiste en desarrollar una herramienta que permita evaluar cÃ³digo fuente contra el Top 10 de vulnerabilidades de OWASP utilizando modelos de lenguaje e inteligencia artificial. La herramienta debe ser capaz de:

- Diagnosticar vulnerabilidades de forma autÃ³noma
- Sugerir correcciones automÃ¡ticas
- Integrarse en el flujo de desarrollo mediante pre-commit hooks
- Proporcionar capacidades de auditorÃ­a para el equipo de AppSec

### Usuarios Objetivo

- **Desarrolladores**: Usuarios principales que consumen la herramienta en su ciclo de desarrollo
- **Equipo de AppSec**: Administradores que monitorean y auditan las evaluaciones, identificando patrones de vulnerabilidades y mÃ©tricas de correcciÃ³n

### Objetivos de Negocio

- Mejorar la seguridad del cÃ³digo fuente
- Reducir vulnerabilidades que lleguen a producciÃ³n
- Facilitar la detecciÃ³n temprana de problemas de seguridad

## SoluciÃ³n Propuesta

### Arquitectura del Sistema

La soluciÃ³n implementa un flujo cliente-servidor con los siguientes componentes:

1. **Cliente (Pre-commit Hook)**
   - Intercepta los commits en el repositorio local
   - Valida la autenticaciÃ³n del usuario
   - EnvÃ­a los cambios (diff) a la API de evaluaciÃ³n
   - Procesa la respuesta y bloquea/permite el commit

2. **Servidor de AutenticaciÃ³n (Auth0)**
   - Implementa OAuth 2.0 con flujo PKCE
   - Genera y valida tokens JWT
   - Gestiona credenciales de usuario

3. **API de EvaluaciÃ³n**
   - Valida tokens JWT
   - Orquesta la evaluaciÃ³n en paralelo contra mÃºltiples vulnerabilidades OWASP
   - Implementa un agente por cada tipo de vulnerabilidad
   - Agrega resultados y responde al cliente

### Flujo de Trabajo

```
Usuario â†’ Cambios en Git â†’ Pre-commit Hook â†’ ValidaciÃ³n de Auth
                                â†“
                         API de EvaluaciÃ³n â†’ Modelos de IA (paralelo)
                                â†“
                    Resultados agregados â†’ DecisiÃ³n (aprobar/rechazar)
```

## Stack TecnolÃ³gico

- **Lenguaje**: Python
- **Framework Web**: FastAPI con Pydantic para validaciones
- **Framework de Agentes**: Strands Agents (AWS)
- **Proveedor LLM**: OpenAI
- **AutenticaciÃ³n**: JWT con Auth0 (OAuth 2.0 + PKCE)
- **Pre-commit**: Framework pre-commit

### Estructura del Proyecto

El desarrollo se organizÃ³ en 3 repositorios:

1. **API**: Servidor de evaluaciÃ³n con agentes [pt_appsec_ml_joleal](https://github.com/jlealo12/pt_appsec_ml_joleal)
2. **Hook**: LibrerÃ­a de pre-commit para clientes [pt_appsec_ml_hook](https://github.com/jlealo12/pt_appsec_ml_hook)
3. **Test Repo**: Repositorio de validaciÃ³n de la implementaciÃ³n [pt_appsec_ml_joleal_validation](https://github.com/jlealo12/pt_appsec_ml_joleal_validation)

#### Estructura de respositorios
~~~bash
.
â”œâ”€â”€ pt_appsec_ml_joleal
â”‚Â Â  â”œâ”€â”€ docs
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ arquitectura
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 00-brief.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 01-requisitos.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 02-supuestos.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ 03-diagramas.md
â”‚Â Â  â”‚Â Â  â””â”€â”€ diagramas
â”‚Â Â  â”‚Â Â      â””â”€â”€ diagramas_pt_appsec.drawio
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ Makefile
â”‚Â Â  â”œâ”€â”€ pyproject.toml
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ scripts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ agent_prompts
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ A01_BAC.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ A02_CF.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ A03_Injection.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ connect_to_auth0.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ oauth_login.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ollama_agent_base.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ openai_base_agent.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ openai_owasp_agent.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ openai_owasp_single_agent.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ openai_structured_output_agent.py
â”‚Â Â  â”œâ”€â”€ src
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ agent.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ app.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ auth_utils.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ config.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ configs
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ configs.json
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ prompts
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ A01_BAC.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ A02_CF.md
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ A03_Injection.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ utils.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ workflow.py
â”‚Â Â  â”œâ”€â”€ tests
â”‚Â Â  â””â”€â”€ uv.lock
â”œâ”€â”€ pt_appsec_ml_hook
â”‚Â Â  â”œâ”€â”€ hooks
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ auth_manager.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ hook.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ oauth_login.py
â”‚Â Â  â”œâ”€â”€ Makefile
â”‚Â Â  â”œâ”€â”€ pyproject.toml
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â””â”€â”€ uv.lock
â””â”€â”€ pt_appsec_ml_joleal_validation
    â”œâ”€â”€ main.py
    â”œâ”€â”€ Makefile
    â”œâ”€â”€ pyproject.toml
    â”œâ”€â”€ README.md
    â”œâ”€â”€ test-pre-commit.py
    â””â”€â”€ uv.lock
~~~

## DocumentaciÃ³n tÃ©cnica de la prueba

[DocumentaciÃ³n](docs/)

## Estado de ImplementaciÃ³n

### Funcionalidades Completadas

âœ… API funcional que evalÃºa cÃ³digo contra las 3 primeras vulnerabilidades OWASP  
âœ… Endpoint `/evaluate` para anÃ¡lisis de fragmentos de cÃ³digo  
âœ… Ruta `/validate` preparada (sin implementaciÃ³n completa)  
âœ… Pre-commit hook configurado con ciclo de autenticaciÃ³n  
âœ… Flujo completo de autenticaciÃ³n OAuth 2.0 con PKCE  
âœ… Almacenamiento de credenciales en archivo JSON local  
âœ… Validaciones funcionales bÃ¡sicas del sistema

### Pendientes

âŒ ImplementaciÃ³n completa del endpoint `/validate` para commits  
âŒ Tabla de auditorÃ­a para registro de validaciones  
âŒ IntegraciÃ³n con guardrails para protecciÃ³n contra prompt injection  
âŒ Sistema de cachÃ© basado en hash de commits  
âŒ Pruebas de performance y estrÃ©s  
âŒ EvaluaciÃ³n de los 10 riesgos completos de OWASP  
âŒ Despliegue en nube y anÃ¡lisis de costos

## Observaciones CrÃ­ticas

### 1. Latencia y Experiencia de Usuario

âš ï¸ **DesafÃ­o Principal**: Los modelos de lenguaje tienen latencias naturalmente altas (varios segundos), lo que puede afectar negativamente la experiencia de desarrollo si se implementa como bloqueante en pre-commit.

**RecomendaciÃ³n**: Considerar mover la validaciÃ³n bloqueante al pipeline de CI/CD en lugar del pre-commit, permitiendo que los desarrolladores validen opcionalmente en local.

### 2. Vulnerabilidades de Seguridad

#### Prompt Injection

ğŸ”´ **CrÃ­tico**: El sistema es susceptible a ataques de prompt injection. Ejemplos detectados:

- Uso de secuencias de cierre para engaÃ±ar al modelo
- Instrucciones que hacen pasar cÃ³digo malicioso como ejemplos
- Ejemplo: `print("Hello World")` puede ser inyectado como cÃ³digo vÃ¡lido

**Necesidades**:
- ImplementaciÃ³n de guardrails
- SanitizaciÃ³n de inputs
- ValidaciÃ³n de tags y caracteres especiales (con cuidado de no afectar cÃ³digo legÃ­timo como XML/Markdown)

#### GestiÃ³n de Prompts

Los prompts deben:
- Almacenarse fuera del cÃ³digo (S3 con KMS, Secrets Manager, Parameter Store)
- No ser accesibles por el cliente
- Estar protegidos contra extracciÃ³n mediante prompt hacking

### 3. Escalabilidad

**DesafÃ­os identificados**:
- 10 peticiones paralelas por commit (una por vulnerabilidad OWASP)
- Multiplicado por el nÃºmero de desarrolladores activos
- Sin sistema de cachÃ© implementado

**Soluciones propuestas**:
- Sistema de cachÃ© basado en hash de commits
- EvaluaciÃ³n incremental (solo cÃ³digo modificado)
- OptimizaciÃ³n de modelos y proveedores

### 4. Limitaciones de los Modelos

- **Alucinaciones**: Los modelos pueden generar falsos positivos/negativos
- **Calidad variable**: Dependiendo del tipo de cÃ³digo y vulnerabilidad
- **Costo**: El uso intensivo de APIs de OpenAI puede ser costoso a escala

## Trabajo Futuro Recomendado

### Prioridad Alta

1. **Implementar guardrails** para protecciÃ³n contra prompt injection
2. **Sistema de cachÃ©** para optimizar performance
3. **Tabla de auditorÃ­a** con registro de todas las validaciones
4. **Definir llave de integridad** (hash de commit recomendado)

### Prioridad Media

5. Completar evaluaciÃ³n de las 10 vulnerabilidades OWASP
6. Pruebas de performance y benchmarking
7. ComparaciÃ³n de modelos y proveedores
8. Refinamiento de prompts basado en evaluaciones

### Prioridad Baja

9. Fine-tuning de modelos para casos especÃ­ficos
10. IntegraciÃ³n con herramientas empresariales existentes
11. Dashboard de analÃ­tica para AppSec
12. Despliegue en nube con anÃ¡lisis de costos

## Notas Importantes

- El Top 10 de OWASP son recomendaciones mÃ­nimas, no un programa completo de seguridad
- Se recomienda alinear las evaluaciones con el programa de AppSec especÃ­fico de la organizaciÃ³n
- La validaciÃ³n opcional en local + bloqueante en CI/CD ofrece mejor balance entre seguridad y experiencia de desarrollo
